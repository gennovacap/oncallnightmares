Speaker 1: you're listening to the on call nightmares podcast in every week. I'd go out of my way to do my best to bring you conversations with technologists who spent time on call on. I say that jokingly, because I really do go out of my way to get one every week. So far, I've only missed one week, and, um, I must say that it's It's been difficult sometimes to find people, so I really do need your help. And if you'd like to take part in the podcast, it's pretty easy to do. First of all, you can send me an email. It's on call nightmares at gmail dot com, or you can reach out on Twitter. It's at on call Nightmare on Twitter or at J Destro for me personally. So this week I am back here in New York City. Um, you kind of can hear Rego grumbling in the background. See? Okay, of course. This time my eye makes a quiet time for him to make some sounds. He goes quiet on me. Thanks. We go. Thanks for the embarrassment, anyway. That's my dog. We go anyhow. I'm home this week after week last in Seattle for Microsoft build and bits of bill, which were to events that took pardon coming up this week. I'll be at Chef calm for a little bit. Uh, I'll also be at develop States Toronto coming up and then I'm also making plans to be at Dev Ops Days, Portland and Dev Ops Days in Chicago. I have purchased a digital recorder, which I'd like to use for in person interviews. So if you'd like to be part, make sure you let me know you're gonna be one of those events will find a quiet spot and then we'll be one of these interviews. I think you'd be really fun. So getting onto this week's interview this week, I speak to a buddy of mine that I met, I guess just because of the Dev Ops community, I think that one of the most important parts about being involved in the Dev Ops community is the people that it's really connected me to. They are tremendously important to my career in my life. Now they bring me, ah, lot of joy it and hearing what they're up to and finding out about their stories. And Rich is one of those people. So let's take a listen to this interview I did with Ridge Burrows. He's of Gremlin, which is a chaos. Engineering is a service company, and I think if you're building for resiliency, it's something you should take a look at. So let's take a listen to this interview with Rich, and then we'll close up the pot gas this week. All right? Thanks. And you're listening once again to the Uncle Magnus podcasts. And every week I bring you conversations with technologists who have spent time on call. So, you know, last time I spoke with someone from Gremlin, I felt it was a enlightening conversation with one of the founders. And, well, I couldn't bring you another founder again. I brought you someone I think is it's pretty damn cool. Um, Rich Burrows is a community manager, a gremlin, and he's focused on growing and strengthening their chaos. Engineer engineering community. Yeah, because I, uh Let's face it, folks, I get tongue tied. I'm from Staten Island. Yeah, before he worked it Ah, Gremlin. He worked over at Puppet as an S R E and in other operational rules over the years. What did you say? Ah 20 something years as a ah is a person and uncle. Is that right? Rich?

Speaker 2: Yeah. On and off. I mean, I think

Speaker 1: the whole total of the time that I was in irritations is probably about 20 years. Yeah, I can say that I was probably on call consecutively between jobs, maybe for, like, 10 years. Yeah, but within a 20 curry a 20 year. So career, I'd say, you know, I was on call me t 50 to 60% of it. Maybe 65%. Yeah. So it's all about I guess what You end up moving into later, and you're totally

Speaker 2: I mean, my first job. I was sys admin at a small eyes peon like 1996. Right? And I got handed a pager and I was on call for everything all the time.

Speaker 1: You're your first foray into on call. Like I didn't even Yeah, ask that question. You gave it to me, so

Speaker 2: yeah, we didn't really like and back then, you know, it was my first, my first job in the industry. And so I didn't even really know, like, how on call should work or the fact that it was sort of insane that I was, like, on call all the time.

Speaker 1: Well, you know, it's funny. Is it 1996? I don't know if anybody really knew how on call worked, and that's the funny part about how a lot of us who got our starts I would say between, like, 96 to 2006. We got the full brunt of how do you do it wrong? Because that was a big period off. Fast growth then plummeted. Just complete plummeting of the industry. And then another period of just tremendously rapid growth. So it's crazy to have been, you know, I can see you know, you've been part of that, you see, in the change in the culture around on call, long as I have. So tell me, after you you, uh you were at that small eyes. P the pager all the time. What happened after that? Where did you go that maybe you were on call?

Speaker 2: Yeah. So my next my next gig after that was I. I worked at WebMD, um, s O I was the guy who used to deploy the web md dot com site, which, at that point in time. This is like late nineties, you know, It was they were taking out Super Bowl, lads. You know, it was a super high traffic and very, very visible on dhe, then job Java stuff. Yeah, it was. In fact, we had our own job. A Web server. We had a custom web server that was written in Java.

Speaker 1: Yeah, I had to imagine. And a lot of that stuff is job. Uh, what, what year? You talk about 90 90,000?

Speaker 2: Uh, yeah. It was like 98 to 2000 when the bubble burst. We were going on the front end of the bubble bursting, and so they ended up closing her office, and then I worked in a small web hosting company. After that, I wasn't really on call much there on dhe. Then I went to this company that that I was at for about 10 years. So it was again the Java shop. Um, we did, ah, financial transactions. So, like gift and loyalty card. So we had point of sale devices out in the field that we're sending, you know, transactions into our front and on. Guy was there for about five years and then we got acquired. And then I stuck around for, like, another five. Um, and then I had, like, one job in between there and puppet, I think. And

Speaker 1: so, though, just to talk about that one job where you were supporting these, like, point of sale. Now, this is probably pre like WiFi devices, right? Like, are these, like, point of sale using some sort of local lands for, um, are you part of supporting that as well?

Speaker 2: I didn't have a lot to do with the actual point of sale end, but there were There were some physical point of sale devices that people bought, but they're also were some goofy things. Like there were some boxes that ran, like when those x p that's like point of sale applications on them. And so it was, I think, a pretty big range of of things. And I think some of the device is probably were wireless. So even a tough

Speaker 1: Okay, I got you cool. So let's move a little bit. Ford, you goto puppet on their urine s sorry. And there you're seeing. What year is this? Maybe

Speaker 2: so. Um, I was there for about a year and 1/2 and I left

Speaker 1: there about a year ago. Okay, so around 14 it's a 14 on the public. You're seeing production systems related to people using Puppet

Speaker 2: s o the puppet. I started team, at least in the in the point of time that I was there was interesting in that, um, we didn't. We're so the company wasn't a sass, right? Their main product was this software that that you install on Prem. And so, while we did have some some properties that were in the cloud that we worried about, like they have this thing called Puppet Forage, which is how people share puppet modules with each other. And the team that I was on, we were the ones who were responsible for operating that and for its availability. But a lot of our focus,

Speaker 1: like remote managed service, is for these people in a

Speaker 2: way. Uh, no, not really. The big thing that we've actually focused on as a team. Waas was our internal. See, I pipeline because we were shipping on Prem software, you know? See, I was like, one of the most important things, you know, that that we did it is an engineer, I mork. And so that was really the big focus of the team that I was on. The other thing that we did is we we, uh, dog food, puppet enterprise, the commercial product. And so we we ran an installation of it eternally, that we used to manage our own infrastructure and gave feedback to product management and an engineering and things like that.

Speaker 1: I got you. So you were spending a lot of time. Just mostly keeping what puppet is going is Ah ah, software shop. It's just building the new versions, testing the new versions, getting those releases out, probably working with release engineers or something. That gap. Yeah, like I had full read on the show a few weeks back and, yeah, a lot about release engineering and their role in this lake delivery process. And it's pretty amazing to hear some of the work that goes into that. And, ah, you know how it goes all the way down to the S R. Reason eventually maintaining all the service is that eventually are being deployed. Wait, we're really Yeah. We had a

Speaker 2: really talented Ruiz engineering team there, and I think that they were like 60% women. Something like that, which

Speaker 1: was pretty rad. Too nice. That's Ah, that's really cool to hear. So we go for two puppet, you jump around, sense you for a little bit, and you start making kind of a transition in your career. And now you're over a gremlin. Just kind of helping people learn about chaos, engineering. But before we talk about that stuff, yeah, before we talk about that stuff, uh, well, it's interesting how you know people in this industry, we have people who you kind of you meet and you have, I guess, a great report with because you have similar career paths. And, you know, when I get to talk to you, it's been really great to be able to get to know you, you know? And it's one of the reasons why I'm really glad we get to have this conversation. I don't always just have on friends. I have a lot of strangers on this show, but it's really cool to be ableto have someone on that. You know, I've met because of this business and a lot of it around. You know, people who have tried building things and talking about what they've built and going out the world. And, you know, I I feel that you've got a great story and why I wanted people to kind of hear from you. So thanks a lot. Yeah. You know, this the intro was long, but I wanted to be able to kind of lead into some It was more than just, you know, a bio. I just wanted to say Yeah, being part of

Speaker 2: it. Yeah, honestly, part of the reason why I made this transition and got out of operations was the fact that I had been on call for so long, and I really I really do think it It had some negative impacts on me and I, you know, I was thinking about it and it was like, I don't want to be 65 years old and have pager duty waking me out right? Like there's at some point I've got him on to something else and a tte. First, I thought that was gonna be product management, but I feel like community management is isn't even a better fit for

Speaker 1: me? That's great. And, you know, the thing is, for some people, there's no problem with being 65 on call. I think it's it's simply a decision that people make about where they feel like their lifestyle, their career. It's some people thrive on on call, and that's why we keep the podcast going, because I've found a lot of people who have reached out to me. He told me, You know, I'm on call. I get a lot of

Speaker 2: these stories So, um, definitely there definitely are positive things about it, you know? I mean, I I tend it when I talk about being on call. I tend to talk about the negatives a lot more, but the reality is that it can be really fun sometimes and dealing with weird incidents and things. There's there's like this kind of team bonding that happens when you're all kind of going through the fire together and and there, there, Ah, that that can be really fun. At times

Speaker 1: I think that there is an emotional amount of labor that is spent and, you know, in the last conversation I had, you know, this is work and it does cause trauma. You know, the last conversation I had with my Julian, you know. He reminded me t o to make sure that I take this seriously. That would say, you know, their situations. That could be, you know, dramatic two people that can really impact you because of

Speaker 2: the time. And I respect that more and more of the After

Speaker 1: I talked to people week to week with these stories. I don't want to get into yours in just a second, but I think one of the things that I've really got from all these stories is that everybody in the end wants to just help someone get a little bit better, whether it's the application that they're running there, um, their service, a website, even the people that they work alongside. And I think that's why um, it's fun to do this podcast because it's great to collect the stories and listen to how people want to get better.

Speaker 2: Yeah, I think that I really like the point of view, and I don't think I I came across this before I got sort of involved in the de bop States community. But I feel like that idea that, you know, you're sort of based assumption is that everybody that you work with is doing their best to do their job. Right, Um, And until you've seen some real specific evidence to the contrary, um, you know, assumed that everybody has the best intent. And, you know, like you said, warning is really important. If we're not warning, we're not growing, and we're going to get burned out.

Speaker 1: Yeah, I think the only things they don't have good intent or servers servers, just with what you put in them, you know what I mean? You look, that you work with, for the most part, I think have best intent what they dio. It's what happens when you deploy what you build together. That's where you learn, I think, who put in the most time thinking about other people's time and, yeah, like, who created tests that checked for certain things who did security, you know, pen tests against the software to ensure that there wouldn't be any sort of cross site scripting that encouraged. And then who assured, you know, the database calls that occurred, you know, we're going to be cashed at certain levels that didn't overload. You are big database. Yep. And I think that that's the rial interesting part of how modern operations has changed things well.

Speaker 2: And and I think even even, you know, if books do you have the best of intentions. They're still operating under constraints, right? We've all nobody has an unlimited amount of time or, you know, unlimited staffing. And so, you know, we're always making priority decisions about you know, what we should be working on improving and nobody nobody gets to do exactly what they want. And

Speaker 1: I think in like the Dev ops World now that we have, it's it's much easier to avoid those situations where coat gets written thrown over the wall and then someone deploys it. You find out afterwards all the bad stuff that happens. I think that you know that thinking about other people and I guess what you know. Software development and operators who use, you know, operational intelligence or emotional intelligence. Yeah, and and work with empathy, I think, is what leads to those problems not being quite his Biggs, but I think

Speaker 2: that's it. That's it. Yeah, let me just say really quickly that that's been a big shift in my career, like as a person. There's a point in time, Andi think It's a kind of time period that we're gonna be talking about, where I literally I yelled it. People sometimes in the office, right, I would get so upset about something that the engineers had done, that I would be like yelling at people. And, um and that's that's again. I think something really important that I've gotten out of the hole Dev. Ops move. It has been that focus on empathy, and I think that I've done a real 1 80 when it comes to some of those things I don't I can't imagine myself behaving like that now, you know. But but part of it, too, is that I was under a lot of pressure and I was dealing with painful situations that other people's decisions have put me into. That was, that was my reaction sometimes was to just kind of explode.

Speaker 1: Yeah, Unfortunately, a lot of us are Leone, and you don't realize it until someone says, You just can't do that. Um, are lashing out. Uh, What? Let's Let's let's move on, Thio Little bit portion of the podcast that I call the rules. So I'd like to hear a story from you being on call. But before you tell me that story, I just want to make sure that you know the rules. I tell every cell single week they are not that tough. So don't incriminate yourself. Because, you know, if you did something I don't want you to get trouble. Don't incriminate others. Because, remember, we're always blameless when we do retrospectives and help us learn. Because that's what this podcast is its retrospective. So why don't you give me, ah, story about a nasty kind of impact that happened or actually say issue that happened. You know, maybe you had an outage from a phone call? Uh, yeah. Patient. Yes, you did. You get?

Speaker 2: Yeah. So the best one I could think of is is probably the most painful outage I've been through in my career. Never be honest. I can't I can't promise that I was the person who was on call this. This happened at that shop that I was at for a long time That did the, you know, transactions from the point of sales. And I mean this This probably would have been, like, maybe 7 4008 So I know I don't remember if I'm the person who actually caught the word. But it was one of those incidents that was big enough where, like everybody was pretty much involved. Like our whole operation's t even and a good chunk of the engineering team. We're all, like, actively dealing with this issue for for days. So So what happened is we eso We had active active data centers. Right, sweetie? Today the centers, we're taking traffic from these point of sale devices. They are ground into one of the two d n A. To to data centers based on D. N s entries. Right. They each customer has their own DNA girl, but they hit and they're generally pointed at one of the two data centers and we ended up having a power outage in what we considered our backup data center. It was the one that we took less traffic at, but it was still taking about 1/3 of the traffic that we did on a daily basis.

Speaker 1: And your assumption is it that the primaries up, you should be able to get through that. The assumption,

Speaker 2: Right? Right. But But it's scary, right? Because when you're only running on that primary. The next thought is Well, what happens if we have an outage on the primary? You know, then we're then we're completely down. And so so even being in that situation where we're running like in a in a kind of degraded mood with super uncomfortable and something that we didn't wanna have to sustain for any longer than then was possible. So so, yeah, it was just a weird thing. We just get a power outage. I can't remember the whole story, But I you know, the gist of it was that we thought that there should have been back up power and there wasn't. So, uh, so there was a power that of some kind of ended up frying our course, which they're on dso We were just hard down in that data center like we couldn't do anything.

Speaker 1: So now here's a question about that. Um and this goes into brought remediation sze or after what you learned from the situation, is one. Did it end up? Ah, going into a situation where you found out that it was your individual devices that needed some sort of power of redundancy or was it the, um the actual data center that you were like using leasing own whatever it was, didn't have the proper, like redundancy. What? Which would you say waas?

Speaker 2: It was the data center, okay? And so, oddly enough, one of our we after this incident, we actually became very concerned about data center power. It was It was something that, you know, became very important to us after we will through this pain. But ironically, we actually had a power related incident in our other data center. Just, I think, like, two years later, and that was a data center that actually did have backup power that should have worked. But it had taken the backup power down for, like, five minutes to do some sort of data, some sort of maintenance. And during that five minute period, there was an event on the power grid, and and we ended up going down there, too. So but the 1st 1 was worse because we literally you know, like I said, we fried our course switch. And so not only is everything down, but we don't have another piece of hardware that we can just stick in the rack right

Speaker 1: here. That Yeah, just a CZ you can't even I mean, unless you, like, run down to the rack switch store and get you on which, what year was this B

Speaker 2: I You know, I would guess that this was probably about 2008. 2009. Yeah. Alright. Even earlier than that

Speaker 1: to get yourself a course which, you know, you needed least elite of Ah, on one day. So, uh, I can see where to be. Kind of difficult, because, you know, you're talking about a time where you couldn't just go on on Amazon and say, Yeah, you know what? I need this. Cisco, blah, blah, blah get Don't need 15 minutes in a configuration. The configuration was really

Speaker 2: complex, so we actually were using. We were using Cisco switches, and we had, uh, violence or modules, like on the switch. And so we were using the switch itself to your load balancing. So they're the configuration for the device itself. Was kind of insane with

Speaker 1: their backups for that. Or did you have to just work with Cisco to reconfigure everything?

Speaker 2: I think the network engineer, our network engineer didn't actually have access to the config. Um uh, this was one of the other sort of painful parts about the incident. That kind of personal level is that we had one network engineer and he was on his honeymoon in Hawaii when this and so he got to work through much of his honeymoon because we had lost the switch. Now I have to say in the company's defense, they did. They did, trying to make that right. They bought him another trip to Hawaii. Later on, they paid for completely. But yeah, it was It was

Speaker 1: pretty brutal. Yeah, I think that we learn about how much fun call can be brutal for those of us when you don't make plans for when, Like that one person is going out of town. And that's one of the things I've learned a lot about, I guess. Better. Modern, um, rotations is that people seem to have better backup plans. Yeah, and really don't necessarily put one person in that position to be, you know, always getting the brunt of everything. Because I I've definitely been in a position where, you know, I had one boss. I was the only person that that person, the only boss, you know that person employed. I worked for him. I did what he wanted. And it was a for the morning of server wasn't responding. I had to take care. There was nobody else. Yeah, you know, learning about that at how much that can take. A toll of u told me about how much better on call that really be. And it's good to see that it's actually become part of the DNA of a lot of companies. Yeah, they'll actually tell, you know, everybody from this team, his own call. This is how we do the rotation during, like, interviews. And I get a lot of I get a really impressed by

Speaker 2: that. Yeah. I mean, and I will absolutely asked about that. If I'm interviewing for an ops role. If they don't bring it up, that's definitely gonna be one of the questions on my

Speaker 1: list. Yeah, So let me ask you a little bit more. You hurted this work for gremlin now, depth. And you've learned about chaos. But what was the chaos that came out of that

Speaker 2: outage? Uh, you pop knows. No, it's it's actually it's really funny, because, I mean, this is, you know, in, um in chaos, engineering the frame of reference that a lot of people have this chaos right, which is thing that that Netflix built that would go in and randomly shut down. There was an easy two instances. Well, this was sort of a shutdown. It just happened to be the entire data center, and it wasn't planned. So

Speaker 1: jury it What? I was going to say we're finished with this kind of a new unplanned chaos. If being on call, you know what's something that you really would say to someone? This is what I've learned from this incident, that that's the best. One of the things I know. I was a roundabout way.

Speaker 2: Yeah. Hey, office, what was learned? So I think one of the biggest things that we learned was how we could deal with some of the issues that that had arisen through the applications that we had. So So this was sort of pre micro Service's days, right? The company ended up like adopting a bunch of micro Service's later on. But at this point, we kind of had three monoliths. There was a monolith that took the front in traffic. There is a mano with that, uh, that wrote down stuff in a database for reporting. And then there was another service that what is, like an auditing service, Basically, And it would. It kind of wrote down everything s so it would take all the Java objects and shove them into database. And what we actually ended up finding out and knew about this capability but hadn't ever exercised it to this extent is that using that oddity to base, we actually were able to replay previous transactions and send them out again on the message bus. And so excuse me. So what we ended up doing is way had through all of this stuff that happened, you know, in that backup data center, the one that had the failure, we have awesome data we had missed. The message is, in essence, that that should have been delivered, but just we're never going to be delivered. And so one of our focus is was You know, before we bring this thing back on line, we've got to get that data into their right. And it was too much data to just kind of shit over the wire back in those days. And so we ended up, um, you know, using this capability that was in our software, you know, to kind of replay all these messages. And I think the engineers did make some changes to it. They made it like, multi threaded and some things like that, you know, kind of improve the performance of it, but, um, but it was something that, um that we we didn't necessarily have a run book for, right? Like, we didn't have a plan for how to deal with this kind of outage, and and, um, we ended up getting through it pretty well. I think so. Besides, the fact that, like understanding that applications and how they work was important. I think the other big thing is that we were a group of people who I think work pretty well together. And we had that sort of team vibe. I think, you know, had each other's back. And, you know, we all pitched in and worked really hard, you know, for a few days until we got stuff under control. And that's that's a situation that I think would have been a lot worse in in a shop where people maybe didn't you know, like each other and didn't like working with each other. And weren't, you know, willing to sort of, like, jump

Speaker 1: into the fire together. That makes a lot of sense. Having a sense of camaraderie, especially when things were not really going well, isn't ground. It's not necessary. But it certainly helps.

Speaker 2: Yeah, we were, you know, looking out for each other and thinking about each other. Like, you know, are people getting sleep? Are they eating? Oh, all that kind of stuff for those are things you have to think about. You know, when you're here, the major incident, you know, And And, um, you know, this is probably I think the the the longest incident that I've been involved with in terms of the time span of it. And I think that it was probably, like, at least like, four days before we got that data center back online and taking traffic again. Andi and well, we're working pretty much around the clock in that time period.

Speaker 1: Gotcha. So let's let's move. Ah, along little forward. Yeah. No. And let me ask you, um, if, uh, if you were on call right now, what advice would you want? Someone to give you.

Speaker 2: So, um, I think I think that probably the biggest one, honestly, is that you've got to take care of yourself, right? Um like, like I said, I hopefully you know, hopefully you're in a position where people are thinking about you looking out for you. But one thing that I've learned in my career is that in the end, you know, you can't count on that. You can't count on anyone else to take care of you. You kind of have to be responsible for your care and and so, you know, you know, being able to do some self care being ableto make sure that you used your pto that you're having some fun outside of being on call. I think that sort of stuff is really important.

Speaker 1: Great. That's that's really important stuff. So here's some other questions that I have a tell me a little bit about chaos. Engineering. Tell me about a little bit. What's going on? A gremlin on what you're doing?

Speaker 2: Yeah. So, you know, we have a chaos Engineering sas. So, basically, it's ah, you know, he had stolen agent on your notes or in your communities. Clustering and allows you to do a bunch of different kinds of CASS engineering experiments like injecting, you know, uh, late and see on the network are doing spiking the CPU Want to give a note or adding memory pressure? There's all these kind of, you know, pre pre bait. Uh, types of caste experiments conduce you on dhe. It's it's honestly, it's it's tooling that I wish I would have had, you know, when I was in these roles before, because the thing that I really like about it is that you are doing these experiments proactively. And the hope is that as you're doing them, you're finding problems with the way your distributed system works, that you can correct and and make a more resilient. But but I think that the part that appeals to me even more than that is the the fact that it's a way to like weren't about your system more right. Like you're you know, you're coming up with the hypothesis about how you think the system is gonna behave, and then you check and see if that's really true, and I think that it gives you a way to get a deeper understanding of how the system is actually functioning, which, you know, when you're suddenly you get that page at three. In the morning. And you know, you get that call from PGA duty or whatever, and you're you know, you're sort of trying to clear your head and figure out what's going on the better that you understand the system. You know, that response

Speaker 1: makes sense to me. Yeah. So tell me what What else you got going on? Anything else you want our listeners to know before we kind of exit onto the end part of this interview?

Speaker 2: Yeah. So I mean, I think the big things that we've actually started a podcast ourselves. So we have a podcast called Break Things on Purpose. That's actually about Cass Engineering. We just published our first episode. Got her 2nd 1 is coming out on May 21st and it's one of my co workers or the two co hosts. And we're basically I'm interviewing somebody every month about you know, what they're doing with Cass and hearing what they're practices. Like the things that learn We've done like three of you so far. Er, and it's super fun to get to talk to people. I'm sure you have the same experience, you know, to get to hear people's stories and and the kinds of things that they're warning.

Speaker 1: Yeah, storytelling is really what I love doing and how hearing other people just tell me about there. They're they're false in their and their ability to rise up from faults is always super important. So that's why I'm doing my best to capture as many of them as possible.

Speaker 2: Yeah, I think it's great. And, you know, we're working stuff, too. You know, every time we talk to one of these people would come away with, you know, something that we hadn't necessarily thought of before. But yeah, it's been a lot of fun. It's called Break Things on Purpose. If people were on, like apple, podcasting play and stitcher and uh oh, that spotify. So if you just search for the name or we we have a Twitter account to, it's just a beauty. Oh, pea pod. Um, and that's a good place to get more information about it, too.

Speaker 1: Well, I'll make sure that I put this in the episode notes of people knowing ago. All right, everybody, thanks a lot for listening to myself and rich mostly catch up and being buddies and talk about the old career. A nonsense. But for most of anything for for listening to us learn from one another so rich. Thanks so much for being on our

Speaker 2: guests. Thanks a lot for having

Speaker 1: me. You got it. We'll be right back with, uh, the end of the podcast. Okay, we'll see that. Thanks a lot, Rich. Well, that's this week's on call nightmares. Thanks a lot for listing. You know, it's been what month since I've started this. I think I got started around December, and I'm really glad that I've been able to keep it going. And I would only keep it going if people were listening. And it seems like you are so thanks very much. Keep up the the e mails and tweets and anything you can to make sure that you're part of this project because it's become really, really cool to be able to collect these stories. So we'll see you next week. I will be like I said in Seattle. So hopefully I can cash a cool interview while I'm there and give you another great episode of uncle nightmares. So catch you next week

